import os
import requests
import pandas as pd
from Scraper import SupabaseScraper
from Processor import DataProcessor

BOT_TOKEN = os.getenv("BOT_TOKEN")
CHAT_ID = os.getenv("CHAT_ID")

def main():
    try:
        scraper = SupabaseScraper()
        raw_data = scraper.fetch_raw_data()
        
        processor = DataProcessor()
        df = processor.process_data(raw_data)
        
        # ÙØ­Øµ Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ØµÙˆØ±: Ù‡Ù„ ÙƒÙ„ ØµÙ Ù„Ù‡ Ø±Ø§Ø¨Ø·ØŸ
        total_rows = len(df)
        rows_with_images = df[df['image_search_link'] != ""].shape[0]
        missing_images = total_rows - rows_with_images
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ø¯Ø«
        df.to_excel("Across_MENA_Images_Check.xlsx", index=False)
        df.to_json('knowledge_base.json', orient='records', force_ascii=False)

        # Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±
        report = (
            f"ğŸ–¼ï¸ **ØªÙ‚Ø±ÙŠØ± Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ø°ÙƒÙŠ**\n\n"
            f"âœ… Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØµÙÙˆÙ: `{total_rows}`\n"
            f"ğŸ”— ØµÙÙˆÙ Ø¨Ø±ÙˆØ§Ø¨Ø· ØµÙˆØ±: `{rows_with_images}`\n"
            f"âš ï¸ ØµÙÙˆÙ Ù…ÙÙ‚ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±: `{missing_images}`\n\n"
            f"ğŸ“Œ ØªÙ… ØªØ­Ø³ÙŠÙ† ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¨Ø­Ø« Ù„Ø¶Ù…Ø§Ù† Ø¯Ù‚Ø© Ø£Ø¹Ù„Ù‰ ÙÙŠ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø±ÙÙ‚Ø© ÙÙŠ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„."
        )
        
        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ù…Ø¹ Ø§Ù„Ù…Ù„Ù
        url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendDocument"
        with open("Across_MENA_Images_Check.xlsx", 'rb') as f:
            requests.post(url, data={'chat_id': CHAT_ID, 'caption': report, 'parse_mode': 'Markdown'}, files={'document': f})

    except Exception as e:
        requests.post(f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage", data={'chat_id': CHAT_ID, 'text': f"âŒ Ø®Ø·Ø£: {str(e)}"})

if __name__ == "__main__":
    main()
