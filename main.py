import os
import requests
import pandas as pd
from datetime import datetime
from Scraper import SupabaseScraper
from Processor import DataProcessor

# Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª - ØªØ£ÙƒØ¯ Ù…Ù† Ù…Ø·Ø§Ø¨Ù‚ØªÙ‡Ø§ Ù„Ù„Ø£Ø³Ù…Ø§Ø¡ ÙÙŠ GitHub Secrets
BOT_TOKEN = os.getenv("BOT_TOKEN")
CHAT_ID = os.getenv("CHAT_ID")
SITE_URL = os.getenv("SITE_URL")
SITE_TOKEN = os.getenv("SITE_TOKEN")

def send_telegram(message, file_path=None):
    """Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙˆØ§Ù„Ù…Ù„Ù Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù… Ø¨Ù†Øµ Ù†Ø¸ÙŠÙ"""
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/"
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„ØªÙŠ Ù‚Ø¯ ØªØ¹Ø·Ù„ ØªÙ„ÙŠØ¬Ø±Ø§Ù…
    clean_message = message.replace("_", " ").replace("*", "")
    try:
        if file_path and os.path.exists(file_path):
            with open(file_path, 'rb') as f:
                r = requests.post(url + "sendDocument", 
                                  data={'chat_id': CHAT_ID, 'caption': clean_message}, 
                                  files={'document': f})
        else:
            r = requests.post(url + "sendMessage", 
                              data={'chat_id': CHAT_ID, 'text': clean_message})
        print(f"ğŸ“¡ Telegram Response: {r.status_code}")
    except Exception as e:
        print(f"âŒ Telegram Error: {e}")

def post_to_website(file_path):
    if not SITE_URL or not SITE_TOKEN:
        return "âš ï¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ù†Ø§Ù‚ØµØ©"

    headers = {"Authorization": f"Token {SITE_TOKEN}"}
    try:
        with open(file_path, 'rb') as f:
            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù ÙˆØ§Ù„Ø£Ù…Ø± ÙÙŠ Ø·Ù„Ø¨ POST ÙˆØ§Ø­Ø¯
            files = {
                'file': (file_path, f, 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
            }
            # Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ù„Ø£ÙƒØ¨Ø± Ù„Ù†Ø¬Ø§Ø­ Ø§Ù„Ø·Ù„Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ø³Ø§Ø¨Ù‚
            data = {'command': 'import_customs_excel'}
            
            response = requests.post(SITE_URL, headers=headers, files=files, data=data)
            
            print(f"ğŸŒ Website Response: {response.status_code} - {response.text}")
            
            if response.status_code in [200, 201]:
                return "âœ… ØªÙ… Ø§Ù„Ø±ÙØ¹ Ø¨Ù†Ø¬Ø§Ø­"
            else:
                # Ù†Ø±Ø³Ù„ Ø¬Ø²Ø¡Ø§Ù‹ Ù…Ù† Ø±Ø¯ Ø§Ù„Ø³ÙŠØ±ÙØ± Ù„Ù†Ø¹Ø±Ù Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø§ ÙŠØ²Ø§Ù„ ÙŠØ±ÙØ¶ Ø§Ù„Ø£Ù…Ø±
                return f"âŒ ÙØ´Ù„: {response.status_code} ({response.text[:30]})"
    except Exception as e:
        return f"âŒ Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ: {e}"

def main():
    print(f"ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙŠÙˆÙ…ÙŠ: {datetime.now().strftime('%H:%M:%S')}")
    try:
        # 1. Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        scraper = SupabaseScraper()
        raw_data = scraper.fetch_raw_data()
        
        # 2. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ù„Ø¥ÙƒØ³Ù„
        processor = DataProcessor()
        df = processor.process_data(raw_data)
        
        # 3. Ø­ÙØ¸ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„
        file_name = "Across_MENA_Daily_Report.xlsx"
        df.to_excel(file_name, index=False)
        print(f"ğŸ’¾ ØªÙ… ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…Ù„Ù. Ø§Ù„Ø¹Ø¯Ø¯: {len(df)}")

        # 4. Ø§Ù„Ø±ÙØ¹ Ù„Ù„Ù…ÙˆÙ‚Ø¹ (Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø­Ø§Ø³Ù…Ø©)
        web_status = post_to_website(file_name)
        
        # 5. ØªØ¬Ù‡ÙŠØ² ØªÙ‚Ø±ÙŠØ± ØªÙ„ÙŠØ¬Ø±Ø§Ù…
        report = (
            f"Across MENA Daily Update\n"
            f"Date: {datetime.now().strftime('%Y-%m-%d')}\n"
            f"Site Status: {web_status}\n"
            f"Items Count: {len(df)}"
        )
        
        # 6. Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        send_telegram(report, file_name)
        print("ğŸ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§ÙƒØªÙ…Ù„Øª.")

    except Exception as e:
        err = f"Main Error: {str(e)}"
        print(f"âŒ {err}")
        send_telegram(err)

if __name__ == "__main__":
    main()
