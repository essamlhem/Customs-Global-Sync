import os
import requests
import pandas as pd
from datetime import datetime
from Scraper import SupabaseScraper
from Processor import DataProcessor

# Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ù† GitHub Secrets
BOT_TOKEN = os.getenv("BOT_TOKEN")
CHAT_ID = os.getenv("CHAT_ID")
SITE_URL = os.getenv("SITE_URL")
SITE_TOKEN = os.getenv("SITE_TOKEN")

def send_telegram(message, file_path=None):
    """Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙˆØ§Ù„Ù…Ù„Ù Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù… Ø¨Ù†Øµ Ù†Ø¸ÙŠÙ"""
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/"
    clean_message = message.replace("_", " ").replace("*", "")
    try:
        if file_path and os.path.exists(file_path):
            with open(file_path, 'rb') as f:
                requests.post(url + "sendDocument", 
                              data={'chat_id': CHAT_ID, 'caption': clean_message}, 
                              files={'document': f})
        else:
            requests.post(url + "sendMessage", 
                          data={'chat_id': CHAT_ID, 'text': clean_message})
    except Exception as e:
        print(f"âŒ Telegram Error: {e}")

def post_to_website(file_path):
    """Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ÙˆÙ‚Øª ÙˆØ§Ù„Ø§ØªØµØ§Ù„"""
    if not SITE_URL or not SITE_TOKEN:
        return "âš ï¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ù†Ø§Ù‚ØµØ©"

    headers = {"Authorization": f"Token {SITE_TOKEN}"}
    
    try:
        with open(file_path, 'rb') as f:
            files = {'file': f}
            data = {'command': 'import_customs_excel'}
            
            # Ø£Ø¶ÙÙ†Ø§ timeout=300 (5 Ø¯Ù‚Ø§Ø¦Ù‚) Ù„Ù„Ø³Ù…Ø§Ø­ Ù„Ù„Ø³ÙŠØ±ÙØ± Ø¨Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¶Ø®Ù…Ø©
            response = requests.post(
                SITE_URL, 
                headers=headers, 
                files=files, 
                data=data,
                timeout=300 
            )
            
            print(f"ğŸŒ Website Response: {response.status_code} - {response.text}")
            
            if response.status_code in [200, 201]:
                return "âœ… ØªÙ… Ø§Ù„Ø±ÙØ¹ Ø¨Ù†Ø¬Ø§Ø­"
            else:
                return f"âŒ ÙØ´Ù„: {response.status_code} ({response.text[:30]})"
                
    except requests.exceptions.Timeout:
        return "â³ ÙØ´Ù„: ÙˆÙ‚Øª Ù…Ø³ØªÙ‚Ø·Ø¹ (Ø§Ù„Ø³ÙŠØ±ÙØ± Ø¨Ø·ÙŠØ¡)"
    except requests.exceptions.ConnectionError:
        return "ğŸ”Œ ÙØ´Ù„: Ø§Ù†Ù‚Ø·Ø¹ Ø§Ù„Ø§ØªØµØ§Ù„ (Ø¨Ø³Ø¨Ø¨ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù)"
    except Exception as e:
        return f"âŒ Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ: {str(e)[:40]}"

def main():
    print(f"ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙŠÙˆÙ…ÙŠ: {datetime.now().strftime('%H:%M:%S')}")
    try:
        # 1. Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø³ÙˆØ±Ø³
        scraper = SupabaseScraper()
        raw_data = scraper.fetch_raw_data()
        
        # 2. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØ­Ø¶ÙŠØ±Ù‡Ø§
        processor = DataProcessor()
        df = processor.process_data(raw_data)
        
        # 3. Ø­ÙØ¸ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        file_name = "Across_MENA_Daily_Report.xlsx"
        df.to_excel(file_name, index=False)
        print(f"ğŸ’¾ ØªÙ… ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…Ù„Ù. Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {len(df)}")

        # 4. Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø±ÙØ¹ Ù„Ù„Ù…ÙˆÙ‚Ø¹ (Ù…Ø¹ ØµØ¨Ø± Ø£Ø·ÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ±ÙØ±)
        web_status = post_to_website(file_name)
        
        # 5. Ø±Ø³Ø§Ù„Ø© ØªÙ„ÙŠØ¬Ø±Ø§Ù… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        report = (
            f"Across MENA Daily Update\n"
            f"Date: {datetime.now().strftime('%Y-%m-%d')}\n"
            f"Site Status: {web_status}\n"
            f"Items Count: {len(df)}"
        )
        
        send_telegram(report, file_name)
        print("ğŸ ØªÙ…Øª Ø§Ù„Ù…Ù‡Ù…Ø©.")

    except Exception as e:
        err = f"Main Error: {str(e)}"
        print(f"âŒ {err}")
        send_telegram(err)

if __name__ == "__main__":
    main()
